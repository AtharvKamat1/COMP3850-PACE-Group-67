{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4763c18-0e9f-4601-a3e8-309764173be0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Final SNN Implementation (Paper-Reproduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e5005a-c8a0-4dfb-8aea-4e632509e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import arff\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3766284-7826-4f2d-8d74-42a6843ec1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Step 1: Load data\n",
    "# ===========================\n",
    "\n",
    "#step 1 completed\n",
    "\n",
    "# train_df=pd.read_csv(\"Datasets/target_train.csv\")\n",
    "# test_df=pd.read_csv(\"Datasets/target_test.csv\")\n",
    "\n",
    "# sample_matching_df = pairwise_df[pairwise_df['label'] == 1].sample(n=50000, random_state=42)\n",
    "# sample_nonmatching_df = pairwise_df[pairwise_df['label'] == 0].sample(n=50000, random_state=42)\n",
    "# sample_df = pd.concat([sample_matching_df, sample_nonmatching_df]).reset_index(drop=True)\n",
    "\n",
    "# # Optionally, print sample_df to inspect\n",
    "# print(\"Sampled record pairs:\")\n",
    "# print(sample_df[['uid1', 'uid2', 'label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee729cfc-6eb6-45dc-b930-b31ce5f9f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        uid1                                              text1       uid2  \\\n",
      "0  6488772-1  A 38-year-old man presented to our office afte...  7383003-1   \n",
      "1  6069825-1  A 54-year-old male, with alcohol-related liver...  6069825-2   \n",
      "2  2740309-1  A 32-year-old man (white, 75 kg, 182 cm and no...  8225499-1   \n",
      "3  1283745-1  A 59-year-old man was admitted to Coronary Car...  7093274-2   \n",
      "4  6062634-1  A thirty-two-year-old female patient from Mexi...  8245233-2   \n",
      "\n",
      "                                               text2  label  \n",
      "0  A 21 year-old man with an established diagnosi...      0  \n",
      "1  A 47-year-old male, with alcohol-related liver...      1  \n",
      "2  A 19-year-old male patient presented with high...      0  \n",
      "3  A 17-year-old boy was involved in a high-impac...      0  \n",
      "4  A 49-year-old female with a history of nonalco...      0  \n"
     ]
    }
   ],
   "source": [
    "# print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556fbb9f-ceaf-4d41-a759-fdedd2b4f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate embeddings only for train and test separately\n",
    "# import numpy as np\n",
    "# from transformers import BertTokenizer, TFBertModel\n",
    "# import tensorflow as tf\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Load pretrained BERT model and tokenizer\n",
    "# from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# # Load ClinicalBERT\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# bert_model = TFBertModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "\n",
    "# # Helper function for batched embedding generation\n",
    "# def generate_embeddings_batched(texts, batch_size=32, max_length=512):\n",
    "#     all_embeddings = []\n",
    "\n",
    "#     for i in range(0, len(texts), batch_size):\n",
    "#         batch = texts.iloc[i:i+batch_size].tolist()\n",
    "#         inputs = tokenizer(\n",
    "#             batch,\n",
    "#             return_tensors=\"tf\",\n",
    "#             padding=True,\n",
    "#             truncation=True,\n",
    "#             max_length=max_length  # Truncate to 512 tokens\n",
    "#         )\n",
    "#         outputs = bert_model(inputs[\"input_ids\"])\n",
    "#         cls_embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "#         all_embeddings.append(cls_embeddings.numpy())\n",
    "\n",
    "#     return np.vstack(all_embeddings)\n",
    "# # Encode and save embeddings\n",
    "# x1_train = generate_embeddings_batched(train_df['text1'])\n",
    "# x2_train = generate_embeddings_batched(train_df['text2'])\n",
    "# y_train = train_df['label'].values.astype(np.float32)\n",
    "\n",
    "# x1_test = generate_embeddings_batched(test_df['text1'])\n",
    "# x2_test = generate_embeddings_batched(test_df['text2'])\n",
    "# y_test = test_df['label'].values.astype(np.float32)\n",
    "\n",
    "# step 3 completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b239d7c-49ca-4302-a2e6-c55c2abd865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store cached files\n",
    "# os.makedirs(\"clinicalbert\", exist_ok=True)\n",
    "# # save the embeddings for later use\n",
    "# np.save(\"clinicalbert/x1_train.npy\", x1_train)\n",
    "# np.save(\"clinicalbert/x2_train.npy\", x2_train)\n",
    "# np.save(\"clinicalbert/y_train.npy\", y_train)\n",
    "# np.save(\"clinicalbert/x1_test.npy\", x1_test)\n",
    "# np.save(\"clinicalbert/x2_test.npy\", x1_test)\n",
    "# np.save(\"clinicalbert/y_test.npy\", y_test)\n",
    "\n",
    "# For the later experiments load the embeddings using following code\n",
    "x1_train = np.load(\"embeddings/x1_target_train.npy\")\n",
    "x2_train = np.load(\"embeddings/x2_target_train.npy\")\n",
    "y_train = np.load(\"embeddings/y_target_train.npy\")\n",
    "x1_test = np.load(\"embeddings/x1_target_test.npy\")\n",
    "x2_test = np.load(\"embeddings/x2_target_test.npy\")\n",
    "y_test = np.load(\"embeddings/y_target_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5281417a-ef2d-4689-ad31-a4fd78e787ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 28.6171 - val_loss: 16.3957\n",
      "Epoch 2/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 14.4741 - val_loss: 12.7353\n",
      "Epoch 3/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 11.9593 - val_loss: 11.0692\n",
      "Epoch 4/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 10.5261 - val_loss: 10.1080\n",
      "Epoch 5/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.6416 - val_loss: 9.3886\n",
      "Epoch 6/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.8939 - val_loss: 8.7072\n",
      "Epoch 7/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.4023 - val_loss: 8.6148\n",
      "Epoch 8/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.9429 - val_loss: 7.9583\n",
      "Epoch 9/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.6505 - val_loss: 7.6913\n",
      "Epoch 10/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.2594 - val_loss: 7.1162\n",
      "Epoch 11/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.0230 - val_loss: 6.9806\n",
      "Epoch 12/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.7173 - val_loss: 6.6847\n",
      "Epoch 13/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.6403 - val_loss: 6.9700\n",
      "Epoch 14/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.4255 - val_loss: 6.6305\n",
      "Epoch 15/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.1939 - val_loss: 6.8257\n",
      "Epoch 16/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.1282 - val_loss: 6.7108\n",
      "Epoch 17/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.9921 - val_loss: 6.0175\n",
      "Epoch 18/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.8087 - val_loss: 6.3052\n",
      "Epoch 19/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.7361 - val_loss: 5.9058\n",
      "Epoch 20/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.6270 - val_loss: 5.8816\n",
      "Epoch 21/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.4414 - val_loss: 6.2090\n",
      "Epoch 22/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.5803 - val_loss: 6.5045\n",
      "Epoch 23/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.5086 - val_loss: 6.3667\n",
      "Epoch 24/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.2992 - val_loss: 5.8904\n",
      "Epoch 25/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.1946 - val_loss: 5.6085\n",
      "Epoch 26/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.1144 - val_loss: 5.9525\n",
      "Epoch 27/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.3337 - val_loss: 5.7898\n",
      "Epoch 28/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.1227 - val_loss: 5.6512\n",
      "Epoch 29/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.0510 - val_loss: 5.5681\n",
      "Epoch 30/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.1123 - val_loss: 5.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e025dd0cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================\n",
    "# Step 3: Build Siamese Autoencoder\n",
    "# ====================================\n",
    "from tensorflow.keras import layers, regularizers, Model, Input\n",
    "\n",
    "\n",
    "def build_siamese_autoencoder(embedding_dim):\n",
    "    encoder_input = Input(shape=(embedding_dim,))\n",
    "    x = layers.Dense(50, activity_regularizer=regularizers.l1(0.01))(encoder_input)\n",
    "    x = layers.LeakyReLU(negative_slope=0.01)(x)\n",
    "    encoder_output = layers.Dense(embedding_dim)(x)  # Consider linear output\n",
    "    encoder = Model(encoder_input, encoder_output)\n",
    "\n",
    "    decoder_input = Input(shape=(embedding_dim,))\n",
    "    decoder_output = layers.Dense(embedding_dim, activation='sigmoid')(decoder_input)\n",
    "    decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "    input1 = Input(shape=(embedding_dim,))\n",
    "    input2 = Input(shape=(embedding_dim,))\n",
    "    encoded1 = encoder(input1)\n",
    "    encoded2 = encoder(input2)\n",
    "    recon1 = decoder(encoded1)\n",
    "    recon2 = decoder(encoded2)\n",
    "\n",
    "    # Output both encoded and reconstructed vectors\n",
    "    merged_output = layers.Concatenate()([encoded1, encoded2, recon1, recon2])\n",
    "    model = Model(inputs=[input1, input2], outputs=merged_output)\n",
    "    return model, encoder\n",
    "\n",
    "def hybrid_classification_loss(margin=2.5, alpha=1.0):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        emb_dim = tf.shape(y_pred)[1] // 4\n",
    "        encoded1 = y_pred[:, :emb_dim]\n",
    "        encoded2 = y_pred[:, emb_dim:2*emb_dim]\n",
    "        recon1 = y_pred[:, 2*emb_dim:3*emb_dim]\n",
    "        recon2 = y_pred[:, 3*emb_dim:]\n",
    "\n",
    "        # Contrastive loss on encoded vectors\n",
    "        distances = tf.norm(encoded1 - encoded2, axis=1)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        contrastive_loss = y_true * tf.square(distances) + (1 - y_true) * tf.square(tf.maximum(margin - distances, 0))\n",
    "\n",
    "        # True reconstruction loss: input1 vs recon1, input2 vs recon2\n",
    "        recon_loss1 = tf.reduce_mean(tf.square(encoded1 - recon1), axis=1)\n",
    "        recon_loss2 = tf.reduce_mean(tf.square(encoded2 - recon2), axis=1)\n",
    "        recon_loss = 0.5 * (recon_loss1 + recon_loss2)\n",
    "\n",
    "        return tf.reduce_mean(alpha * recon_loss + contrastive_loss)\n",
    "    return loss_fn\n",
    "\n",
    "embedding_dim = x1_train.shape[1]\n",
    "sa_model, encoder = build_siamese_autoencoder(embedding_dim)\n",
    "sa_model.compile(optimizer='adam', loss=hybrid_classification_loss(margin=2.5, alpha=1.0))\n",
    "sa_model.fit([x1_train, x2_train], y_train, epochs=30, batch_size=256, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4eb98e5-a528-4145-9aff-90e33687d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475us/step\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step\n",
      "------ Siamese Autoencoder Evaluation ------\n",
      "Training Accuracy: 0.8141, F1 Score: 0.7962\n",
      "Test Accuracy: 0.7991, F1 Score: 0.7794\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Evaluate the Siamese Autoencoder (Threshold-based)\n",
    "# ==========================================================\n",
    "\n",
    "# Get reconstructions\n",
    "encoded1_train = encoder.predict(x1_train)\n",
    "encoded2_train = encoder.predict(x2_train)\n",
    "encoded1_test = encoder.predict(x1_test)\n",
    "encoded2_test = encoder.predict(x2_test)\n",
    "\n",
    "# Compute Euclidean distances\n",
    "train_distances = np.sqrt(np.sum((encoded1_train - encoded2_train)**2, axis=1))\n",
    "test_distances = np.sqrt(np.sum((encoded1_test - encoded2_test)**2, axis=1))\n",
    "\n",
    "# Use fixed threshold (e.g., 1.0) to classify matches\n",
    "threshold = 1.0\n",
    "train_pred = (train_distances < threshold).astype(int)\n",
    "test_pred = (test_distances < threshold).astype(int)\n",
    "\n",
    "# Accuracy & F1\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "train_f1 = f1_score(y_train, train_pred)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "\n",
    "print(\"------ Siamese Autoencoder Evaluation ------\")\n",
    "print(f\"Training Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e34365-ce31-43bc-97fc-9af5afbdea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7240 - loss: 0.5147 - val_accuracy: 0.7994 - val_loss: 0.4538\n",
      "Epoch 2/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.3940 - val_accuracy: 0.8097 - val_loss: 0.4458\n",
      "Epoch 3/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.3790 - val_accuracy: 0.8044 - val_loss: 0.4488\n",
      "Epoch 4/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3767 - val_accuracy: 0.8041 - val_loss: 0.4291\n",
      "Epoch 5/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3741 - val_accuracy: 0.8084 - val_loss: 0.4276\n",
      "Epoch 6/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3695 - val_accuracy: 0.8119 - val_loss: 0.4269\n",
      "Epoch 7/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3634 - val_accuracy: 0.8000 - val_loss: 0.4330\n",
      "Epoch 8/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3647 - val_accuracy: 0.8009 - val_loss: 0.4372\n",
      "Epoch 9/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.3623 - val_accuracy: 0.8056 - val_loss: 0.4207\n",
      "Epoch 10/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8426 - loss: 0.3564 - val_accuracy: 0.8084 - val_loss: 0.4199\n",
      "Epoch 11/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3563 - val_accuracy: 0.8022 - val_loss: 0.4181\n",
      "Epoch 12/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3550 - val_accuracy: 0.8094 - val_loss: 0.4171\n",
      "Epoch 13/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.3525 - val_accuracy: 0.8047 - val_loss: 0.4250\n",
      "Epoch 14/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3559 - val_accuracy: 0.8016 - val_loss: 0.4245\n",
      "Epoch 15/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3547 - val_accuracy: 0.8047 - val_loss: 0.4168\n",
      "Epoch 16/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.3517 - val_accuracy: 0.8031 - val_loss: 0.4197\n",
      "Epoch 17/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.3522 - val_accuracy: 0.8078 - val_loss: 0.4252\n",
      "Epoch 18/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3534 - val_accuracy: 0.8087 - val_loss: 0.4169\n",
      "Epoch 19/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.3516 - val_accuracy: 0.8097 - val_loss: 0.4168\n",
      "Epoch 20/20\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3491 - val_accuracy: 0.8103 - val_loss: 0.4156\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Step 4: Add Classification Head\n",
    "'''\n",
    "A small feed-forward network (MLP) takes the difference vector as input.\n",
    "Learns non-linear interactions between embedding dimensions.\n",
    "Outputs a probability of match using sigmoid\n",
    "'''\n",
    "# ====================================\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "\n",
    "# Step 1: Get encoded outputs\n",
    "encoded1_train = encoder.predict(x1_train)\n",
    "encoded2_train = encoder.predict(x2_train)\n",
    "encoded1_test = encoder.predict(x1_test)\n",
    "encoded2_test = encoder.predict(x2_test)\n",
    "\n",
    "# Step 2: Compute absolute differences (Siamese-style)\n",
    "diff_train = np.abs(encoded1_train - encoded2_train)\n",
    "diff_test = np.abs(encoded1_test - encoded2_test)\n",
    "\n",
    "# Step 3: Build classification model\n",
    "input_diff = Input(shape=(diff_train.shape[1],))\n",
    "x = Dense(64, activation='relu')(input_diff)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "clf_model = Model(inputs=input_diff, outputs=output)\n",
    "\n",
    "clf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the classifier\n",
    "clf_model.fit(diff_train, y_train, epochs=20, batch_size=256, validation_split=0.1)\n",
    "\n",
    "# Step 5: Evaluate\n",
    "y_pred_prob = clf_model.predict(diff_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print(\"\\nClassifier Evaluation:\")\n",
    "# print(f\"Accuracy: {acc:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n",
    "# print(\"\\nDetailed report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1686d4d-f2e0-4e13-9b0c-60be04db3e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step\n",
      "Classifier Accuracy: 0.813875\n",
      "Classifier F1 Score: 0.8175915717260811\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.79      0.81      4008\n",
      "         1.0       0.80      0.84      0.82      3992\n",
      "\n",
      "    accuracy                           0.81      8000\n",
      "   macro avg       0.81      0.81      0.81      8000\n",
      "weighted avg       0.81      0.81      0.81      8000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Step 5: Evaluation and Visualization\n",
    "# ====================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_prob = clf_model.predict(diff_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Classifier Accuracy:\", acc)\n",
    "print(\"Classifier F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# Save Model\n",
    "#clf_model.save(\"snn_classifier_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52a9323d-7653-4afb-9508-e10505330c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution:\n",
      "0.0    16031\n",
      "1.0    15969\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a9fb044-fac2-4305-b0fc-a7d817afd6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 1.3016 - val_accuracy: 0.8340 - val_loss: 0.7269\n",
      "Epoch 2/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.6085 - val_accuracy: 0.8809 - val_loss: 0.4833\n",
      "Epoch 3/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.4670 - val_accuracy: 0.8781 - val_loss: 0.4135\n",
      "Epoch 4/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8755 - loss: 0.4116 - val_accuracy: 0.8707 - val_loss: 0.4034\n",
      "Epoch 5/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.3897 - val_accuracy: 0.8813 - val_loss: 0.3726\n",
      "Epoch 6/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3871 - val_accuracy: 0.8938 - val_loss: 0.3557\n",
      "Epoch 7/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.3713 - val_accuracy: 0.8832 - val_loss: 0.3623\n",
      "Epoch 8/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.3668 - val_accuracy: 0.8957 - val_loss: 0.3445\n",
      "Epoch 9/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3635 - val_accuracy: 0.8926 - val_loss: 0.3363\n",
      "Epoch 10/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.3585 - val_accuracy: 0.8723 - val_loss: 0.3725\n",
      "Epoch 11/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3567 - val_accuracy: 0.8902 - val_loss: 0.3359\n",
      "Epoch 12/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3539 - val_accuracy: 0.8852 - val_loss: 0.3501\n",
      "Epoch 13/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.3521 - val_accuracy: 0.8832 - val_loss: 0.3502\n",
      "Epoch 14/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.3514 - val_accuracy: 0.8836 - val_loss: 0.3541\n",
      "Epoch 15/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.3454 - val_accuracy: 0.8957 - val_loss: 0.3270\n",
      "Epoch 16/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.3527 - val_accuracy: 0.8941 - val_loss: 0.3319\n",
      "Epoch 17/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.3417 - val_accuracy: 0.8934 - val_loss: 0.3243\n",
      "Epoch 18/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.3448 - val_accuracy: 0.8977 - val_loss: 0.3277\n",
      "Epoch 19/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3444 - val_accuracy: 0.8934 - val_loss: 0.3235\n",
      "Epoch 20/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3435 - val_accuracy: 0.8977 - val_loss: 0.3181\n",
      "Epoch 21/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.3331 - val_accuracy: 0.8969 - val_loss: 0.3154\n",
      "Epoch 22/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3408 - val_accuracy: 0.8875 - val_loss: 0.3337\n",
      "Epoch 23/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.3424 - val_accuracy: 0.8922 - val_loss: 0.3217\n",
      "Epoch 24/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.3364 - val_accuracy: 0.8867 - val_loss: 0.3248\n",
      "Epoch 25/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.3326 - val_accuracy: 0.8887 - val_loss: 0.3206\n",
      "Epoch 26/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.3398 - val_accuracy: 0.8938 - val_loss: 0.3290\n",
      "Epoch 27/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.3359 - val_accuracy: 0.9012 - val_loss: 0.3138\n",
      "Epoch 28/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3412 - val_accuracy: 0.8926 - val_loss: 0.3172\n",
      "Epoch 29/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.3380 - val_accuracy: 0.8926 - val_loss: 0.3241\n",
      "Epoch 30/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.3375 - val_accuracy: 0.9043 - val_loss: 0.3233\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step\n",
      "\n",
      "Best Threshold (on pseudo-val set): 0.44 — Best F1 Score: 0.9048\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step\n",
      "\n",
      "Final Evaluation on Test Set:\n",
      "Accuracy: 0.8989\n",
      "F1 Score: 0.9002\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.88      0.90      4008\n",
      "         1.0       0.89      0.91      0.90      3992\n",
      "\n",
      "    accuracy                           0.90      8000\n",
      "   macro avg       0.90      0.90      0.90      8000\n",
      "weighted avg       0.90      0.90      0.90      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Learn threshold using raw BERT embeddings\n",
    "# =========================================\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 1: Compute absolute differences from raw BERT embeddings\n",
    "# -------------------------------------------------------\n",
    "\n",
    "X_train_full = np.abs(x1_train - x2_train)\n",
    "X_test = np.abs(x1_test - x2_test)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 2: Create pseudo-validation split\n",
    "# -------------------------------------------------------\n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "X_train_full, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 3: Build and Train MLP Classifier\n",
    "# -------------------------------------------------------\n",
    "\n",
    "input_dim = X_train_final.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "clf_model = Model(inputs=input_layer, outputs=output)\n",
    "clf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "clf_model.fit(X_train_final, y_train_final, epochs=30, batch_size=256, validation_split=0.1)\n",
    "# clf_model.save(\"mlp_raw_diff_classifier.h5\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 4: Tune threshold on validation set\n",
    "# -------------------------------------------------------\n",
    "\n",
    "y_val_prob = clf_model.predict(X_val).flatten()\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "    y_pred_val = (y_val_prob >= threshold).astype(int)\n",
    "    _, _, f1, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest Threshold (on pseudo-val set): {best_threshold:.2f} — Best F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 5: Evaluate on true test set using tuned threshold\n",
    "# -------------------------------------------------------\n",
    "\n",
    "y_test_prob = clf_model.predict(X_test).flatten()\n",
    "y_test_pred = (y_test_prob >= best_threshold).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Save predictions\n",
    "pd.DataFrame({\n",
    "\"True Label\": y_test,\n",
    "\"Predicted Label\": y_test_pred,\n",
    "\"Confidence\": y_test_prob\n",
    "}).to_csv(\"final_test_predictions_raw_mlp.csv\", index=False)\n",
    "print(\"Test predictions saved to 'final_test_predictions_raw_mlp.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3b092-ef85-4300-a780-837a40d24ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
